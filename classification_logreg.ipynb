{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "Seperating the attributes from the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>famhist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.057417</td>\n",
       "      <td>1.821099</td>\n",
       "      <td>0.477894</td>\n",
       "      <td>-0.295183</td>\n",
       "      <td>-0.418017</td>\n",
       "      <td>-0.176594</td>\n",
       "      <td>3.274189</td>\n",
       "      <td>0.628654</td>\n",
       "      <td>1.184570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.276789</td>\n",
       "      <td>-0.789382</td>\n",
       "      <td>-0.159507</td>\n",
       "      <td>0.411694</td>\n",
       "      <td>0.193134</td>\n",
       "      <td>0.670646</td>\n",
       "      <td>-0.612081</td>\n",
       "      <td>1.381617</td>\n",
       "      <td>-0.842361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.991731</td>\n",
       "      <td>-0.774141</td>\n",
       "      <td>-0.608585</td>\n",
       "      <td>0.883374</td>\n",
       "      <td>-0.112441</td>\n",
       "      <td>0.734723</td>\n",
       "      <td>-0.540597</td>\n",
       "      <td>0.217947</td>\n",
       "      <td>1.184570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.545310</td>\n",
       "      <td>0.841352</td>\n",
       "      <td>0.806252</td>\n",
       "      <td>1.622382</td>\n",
       "      <td>-0.214300</td>\n",
       "      <td>1.411091</td>\n",
       "      <td>0.294742</td>\n",
       "      <td>1.039361</td>\n",
       "      <td>1.184570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.211103</td>\n",
       "      <td>2.169453</td>\n",
       "      <td>-0.598928</td>\n",
       "      <td>0.305020</td>\n",
       "      <td>0.702427</td>\n",
       "      <td>-0.012842</td>\n",
       "      <td>1.645991</td>\n",
       "      <td>0.423301</td>\n",
       "      <td>1.184570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>3.692037</td>\n",
       "      <td>-0.704470</td>\n",
       "      <td>0.598614</td>\n",
       "      <td>0.811401</td>\n",
       "      <td>1.109862</td>\n",
       "      <td>0.570971</td>\n",
       "      <td>-0.696228</td>\n",
       "      <td>1.039361</td>\n",
       "      <td>-0.842361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2.130781</td>\n",
       "      <td>0.122871</td>\n",
       "      <td>-0.159507</td>\n",
       "      <td>0.860240</td>\n",
       "      <td>-0.112441</td>\n",
       "      <td>0.608942</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>0.628654</td>\n",
       "      <td>-0.842361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>-1.479624</td>\n",
       "      <td>-0.138395</td>\n",
       "      <td>-1.521228</td>\n",
       "      <td>-1.307946</td>\n",
       "      <td>-1.334744</td>\n",
       "      <td>-1.413043</td>\n",
       "      <td>0.391960</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>-0.842361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>-0.991731</td>\n",
       "      <td>0.384137</td>\n",
       "      <td>3.317227</td>\n",
       "      <td>0.691875</td>\n",
       "      <td>1.109862</td>\n",
       "      <td>0.309916</td>\n",
       "      <td>0.282897</td>\n",
       "      <td>-0.192760</td>\n",
       "      <td>-0.842361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>-0.308682</td>\n",
       "      <td>-0.791559</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>1.028605</td>\n",
       "      <td>0.906144</td>\n",
       "      <td>-2.692210</td>\n",
       "      <td>-0.696228</td>\n",
       "      <td>0.217947</td>\n",
       "      <td>1.184570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sbp   tobacco       ldl  adiposity     typea   obesity   alcohol  \\\n",
       "0    1.057417  1.821099  0.477894  -0.295183 -0.418017 -0.176594  3.274189   \n",
       "1    0.276789 -0.789382 -0.159507   0.411694  0.193134  0.670646 -0.612081   \n",
       "2   -0.991731 -0.774141 -0.608585   0.883374 -0.112441  0.734723 -0.540597   \n",
       "3    1.545310  0.841352  0.806252   1.622382 -0.214300  1.411091  0.294742   \n",
       "4   -0.211103  2.169453 -0.598928   0.305020  0.702427 -0.012842  1.645991   \n",
       "..        ...       ...       ...        ...       ...       ...       ...   \n",
       "457  3.692037 -0.704470  0.598614   0.811401  1.109862  0.570971 -0.696228   \n",
       "458  2.130781  0.122871 -0.159507   0.860240 -0.112441  0.608942  0.068445   \n",
       "459 -1.479624 -0.138395 -1.521228  -1.307946 -1.334744 -1.413043  0.391960   \n",
       "460 -0.991731  0.384137  3.317227   0.691875  1.109862  0.309916  0.282897   \n",
       "461 -0.308682 -0.791559  0.038474   1.028605  0.906144 -2.692210 -0.696228   \n",
       "\n",
       "          age   famhist  \n",
       "0    0.628654  1.184570  \n",
       "1    1.381617 -0.842361  \n",
       "2    0.217947  1.184570  \n",
       "3    1.039361  1.184570  \n",
       "4    0.423301  1.184570  \n",
       "..        ...       ...  \n",
       "457  1.039361 -0.842361  \n",
       "458  0.628654 -0.842361  \n",
       "459  0.834008 -0.842361  \n",
       "460 -0.192760 -0.842361  \n",
       "461  0.217947  1.184570  \n",
       "\n",
       "[462 rows x 9 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv(\"heart_data.txt\")\n",
    "\n",
    "cols = ['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age']\n",
    "data = pd.DataFrame([file[col] for col in cols]).T\n",
    "famhist = [1 if val == 'Present' else 0 for val in file['famhist']]\n",
    "data['famhist'] = famhist\n",
    "data = pd.DataFrame(zscore(data, ddof=1))\n",
    "cols.append('famhist')\n",
    "data.columns = cols\n",
    "\n",
    "data_label = pd.DataFrame(file['chd'])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data Temp\n",
    "selection = ['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age']\n",
    "X = data[selection]\n",
    "y = data_label\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[65, 12],\n",
       "       [25, 14]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear') #Defining solver\n",
    "logreg.fit(X_train,y_train) #Modelfitting\n",
    "\n",
    "pred_y_log = logreg.predict(X_test) \n",
    "\n",
    "loss_function_log = nn.MSELoss()\n",
    "\n",
    "print(loss_function_log)\n",
    "\n",
    "# loss_test_log = loss_function_log(pred_y_log.flatten(), y_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, pred_y_log) \n",
    "\n",
    "cnf_matrix \n",
    "\n",
    "\n",
    "def log_reg(x_train: object, x_test: object, y_train: object, y_test: object):\n",
    "\n",
    "    logreg = LogisticRegression(solver='liblinear') #Defining solver\n",
    "    logreg.fit(x_train,y_train) #Modelfitting\n",
    "\n",
    "    pred_y_log = logreg.predict(x_test) \n",
    "\n",
    "    loss_function_log = nn.MSELoss()\n",
    "\n",
    "    loss_test_log = loss_function_log(pred_y_log.flatten(), y_test)\n",
    "\n",
    "\n",
    "log_reg(X_train,X_test,y_train,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 427.9555555555555, 'Predicted label')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names=[0,1] # name  of classes \n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "\n",
    "tick_marks = np.arange(len(class_names)) \n",
    "\n",
    "plt.xticks(tick_marks, class_names) \n",
    "\n",
    "plt.yticks(tick_marks, class_names) \n",
    "\n",
    "# create heatmap \n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g') \n",
    "\n",
    "ax.xaxis.set_label_position(\"top\") \n",
    "\n",
    "plt.tight_layout() \n",
    "\n",
    "plt.title('Confusion matrix', y=1.1) \n",
    "\n",
    "plt.ylabel('Actual label') \n",
    "\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Reg Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [78], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m     loss_function_log \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m     10\u001b[0m     loss_test_log \u001b[39m=\u001b[39m loss_function_log(pred_y_log\u001b[39m.\u001b[39mflatten(), y_test)\n\u001b[0;32m---> 13\u001b[0m log_reg(X_train,X_test,y_train,y_test)\n\u001b[1;32m     17\u001b[0m class_names\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m] \u001b[39m# name  of classes \u001b[39;00m\n\u001b[1;32m     19\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots() \n",
      "Cell \u001b[0;32mIn [78], line 10\u001b[0m, in \u001b[0;36mlog_reg\u001b[0;34m(x_train, x_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      6\u001b[0m pred_y_log \u001b[39m=\u001b[39m logreg\u001b[39m.\u001b[39mpredict(x_test) \n\u001b[1;32m      8\u001b[0m loss_function_log \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m---> 10\u001b[0m loss_test_log \u001b[39m=\u001b[39m loss_function_log(pred_y_log\u001b[39m.\u001b[39;49mflatten(), y_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/functional.py:3281\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3277\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, target):\n\u001b[1;32m   3278\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   3279\u001b[0m         mse_loss, (\u001b[39minput\u001b[39m, target), \u001b[39minput\u001b[39m, target, size_average\u001b[39m=\u001b[39msize_average, reduce\u001b[39m=\u001b[39mreduce, reduction\u001b[39m=\u001b[39mreduction\n\u001b[1;32m   3280\u001b[0m     )\n\u001b[0;32m-> 3281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (target\u001b[39m.\u001b[39;49msize() \u001b[39m==\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()):\n\u001b[1;32m   3282\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   3283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3284\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3285\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()),\n\u001b[1;32m   3286\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   3287\u001b[0m     )\n\u001b[1;32m   3288\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not callable"
     ]
    }
   ],
   "source": [
    "def log_reg(x_train: object, x_test: object, y_train: object, y_test: object):\n",
    "\n",
    "    logreg = LogisticRegression(solver='liblinear') #Defining solver\n",
    "    logreg.fit(x_train,y_train) #Modelfitting\n",
    "\n",
    "    pred_y_log = logreg.predict(x_test) \n",
    "\n",
    "    loss_function_log = nn.MSELoss()\n",
    "\n",
    "    loss_test_log = loss_function_log(pred_y_log.flatten(), y_test)\n",
    "\n",
    "\n",
    "log_reg(X_train,X_test,y_train,y_test)\n",
    "\n",
    "\n",
    "\n",
    "class_names=[0,1] # name  of classes \n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "\n",
    "tick_marks = np.arange(len(class_names)) \n",
    "\n",
    "plt.xticks(tick_marks, class_names) \n",
    "\n",
    "plt.yticks(tick_marks, class_names) \n",
    "\n",
    "# create heatmap \n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g') \n",
    "\n",
    "ax.xaxis.set_label_position(\"top\") \n",
    "\n",
    "plt.tight_layout() \n",
    "\n",
    "plt.title('Confusion matrix', y=1.1) \n",
    "\n",
    "plt.ylabel('Actual label') \n",
    "\n",
    "plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data seperation\n",
    "Seperating the attributes from the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_iterations(x_data: object, y_data: object, epochs: int, hidden_neurons: list, k: int = 10, ):\n",
    "    \n",
    "    k_inner = len(hidden_neurons) # Make as many k-folds as there are hidden neurons\n",
    "    \n",
    "    best_model = np.zeros(shape=k) # The number of hidden neurons for the best models will be stored here\n",
    "    \n",
    "    E_i_NN, final_train_error = np.zeros(shape=k), np.zeros(shape=k) # Error for best model in each k-fold will be stored here\n",
    "    validation_error = np.zeros(shape=(k_inner, k_inner)) # Error for each inner layer will be stored here\n",
    "    \n",
    "    splits_outer = KFold(n_splits = k, shuffle=True, random_state=42) # Defining outer splits\n",
    "    \n",
    "    for i, (train_idx_outer, test_idx_outer) in enumerate(splits_outer.split(x_data)): # Outer k-fold layer\n",
    "        \n",
    "        # Getting \"new\" data set for inner k-folds\n",
    "        x_train_outer = x_data.iloc[train_idx_outer]\n",
    "        y_train_outer = y_data.iloc[train_idx_outer]\n",
    "        \n",
    "        \n",
    "        splits_inner = KFold(n_splits = k_inner, shuffle=True, random_state=42) # Defining inner splits\n",
    "        \n",
    "        for j, (train_idx_inner, test_idx_inner) in enumerate(splits_inner.split(x_train_outer)): # Inner k-fold layer\n",
    "            \n",
    "            for jj, h in enumerate(hidden_neurons):\n",
    "                # Training models on inner k-folds\n",
    "                _, test_loss = ANN_model(epochs, \n",
    "                                        h,\n",
    "                                        x_train_outer, \n",
    "                                        y_train_outer,\n",
    "                                        train_idx_inner,\n",
    "                                        test_idx_inner\n",
    "                                        )\n",
    "            \n",
    "                # We're only interested in the last test error, \n",
    "                # as this defines the total loss for the given model\n",
    "                validation_error[j, jj] = test_loss[-1] \n",
    "            \n",
    "                '''\n",
    "                Put a function here that runs the linear regression or logistic regression\n",
    "                for inner k-folds and find the best lambda value for each outer k-fold\n",
    "                '''\n",
    "        \n",
    "        length_ratio = len(x_train_outer) / len(x_data)\n",
    "        generalization_error = [np.sum(length_ratio * np.array(validation_error_s)) for validation_error_s in validation_error]\n",
    "        \n",
    "        # Run model again for outer layer with best h-value from inner layers\n",
    "        h_best = hidden_neurons[np.argmin(generalization_error)]\n",
    "        train_loss, test_loss = ANN_model(epochs, \n",
    "                                 h_best,\n",
    "                                 x_data, \n",
    "                                 y_data,\n",
    "                                 train_idx_outer,\n",
    "                                 test_idx_outer\n",
    "                                )\n",
    "        \n",
    "        '''\n",
    "        Again put the linear or logistic regression model here \n",
    "        but this time evaluate on the outer k-fold\n",
    "        '''\n",
    "        \n",
    "        best_model[i] = h_best\n",
    "        E_i_NN[i] = test_loss[-1] # Appending last value for test loss in outer layer, this value will go in the final table\n",
    "        final_train_error[i] = train_loss[-1]\n",
    "    \n",
    "    return final_train_error, E_i_NN, best_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
